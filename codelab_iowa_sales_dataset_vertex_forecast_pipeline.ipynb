{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07408a42-6902-4601-bb9e-08097b76ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade google-cloud-core==1.7.1 kfp==1.8.2 google-cloud-aiplatform==1.4.3 google-cloud-storage==1.40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89ba9e-a2c6-440f-9e1a-7bbcb6e71f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c06806-05d6-4f1e-8ad8-71900a78ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -U google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52db0b0-b8c0-462d-8ec6-dfbbe0b6720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -c \"import kfp; print('KFP version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016626bf-7079-4186-807d-ffa676d56bc9",
   "metadata": {},
   "source": [
    "## Set some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2620865-bdb2-4e46-9bf9-467845dc8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "\n",
    "# Required Parameters\n",
    "USER = '<username>'  # @param {type: 'string'} <---CHANGE THIS\n",
    "PROJECT_ID = '<project_id>'  # @param {type: 'string'} <---CHANGE THIS\n",
    "LOCATION = 'us-central1'\n",
    "BUCKET_NAME = \"gs://\" + PROJECT_ID + \"-bucket\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(BUCKET_NAME, USER)\n",
    "\n",
    "  # @param {type: 'string'} <---CHANGE THIS\n",
    "\n",
    "#SERVICE_ACCOUNT = '<service_account>'  # @param {type: 'string'} <---CHANGE THIS\n",
    "\n",
    "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0cc4ed-71b7-42e1-bde8-5cacd8f46f6a",
   "metadata": {},
   "source": [
    "## Define a KFP pipeline that uses the forecasting components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbc18c-5e88-4a16-9553-9e39288e45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from kfp.v2 import components\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2 import compiler\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0219b1e-e974-486d-b566-f18ec7f98ff7",
   "metadata": {},
   "source": [
    "### Define a python function based component:\n",
    "\n",
    "get_predict_table_path: converts the output of ForecastingPreprocessingOp to the inputs of ModelBatchPredictOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49e58e-2901-42cc-9640-ad21261bc100",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(base_image='python:3.9')\n",
    "def get_predict_table_path(\n",
    "  predict_processed_table: dict\n",
    ") -> NamedTuple('Outputs', [('preprocess_bq_uri', str)]):\n",
    "  return predict_processed_table['processed_bigquery_table_uri'],"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88693e32-15be-42fb-8cd0-67e04b403c5e",
   "metadata": {},
   "source": [
    "### Define a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b05997-5e40-4693-9e92-85330fedcdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.experimental import forecasting\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "\n",
    "@dsl.pipeline(name='forecasting-pipeline-{}-{}'.format(USER, str(int(time.time()))))\n",
    "def pipeline(project: str,\n",
    "             location: str,\n",
    "             training_input_table_specs: list,\n",
    "             prediction_input_table_specs: list = [],\n",
    "             preprocessing_bigquery_dataset: str = '',\n",
    "             batch_predict_bigquery_dataset: str = '',\n",
    "             model_feature_columns: list = [],\n",
    "             optimization_objective: str = 'minimize-rmse',\n",
    "             forecast_horizon: int = 1,\n",
    "             budget_milli_node_hours: int = 1000,\n",
    "             ):\n",
    "\n",
    "  # training workflow:\n",
    "  training_validation = forecasting.ForecastingValidationOp(\n",
    "      input_tables=training_input_table_specs,\n",
    "      validation_theme='FORECASTING_TRAINING')\n",
    "  training_preprocess = forecasting.ForecastingPreprocessingOp(\n",
    "      project=project,\n",
    "      input_tables=training_input_table_specs,\n",
    "      preprocessing_bigquery_dataset=preprocessing_bigquery_dataset)\n",
    "  training_preprocess.after(training_validation)\n",
    "  prepare_data_for_train_op = forecasting.ForecastingPrepareDataForTrainOp(\n",
    "    input_tables=training_input_table_specs,\n",
    "    preprocess_metadata=training_preprocess.outputs['preprocess_metadata'],\n",
    "    model_feature_columns=model_feature_columns,\n",
    "  )\n",
    "  dataset_create_op = gcc_aip.TimeSeriesDatasetCreateOp(\n",
    "    display_name='training_dataset',\n",
    "    bq_source=prepare_data_for_train_op.outputs['preprocess_bq_uri'],\n",
    "    project=project,\n",
    "    location=location,\n",
    "  )\n",
    "\n",
    "  train_op = gcc_aip.AutoMLForecastingTrainingJobRunOp(\n",
    "      display_name='train-forecasting-model',\n",
    "      time_series_identifier_column=(\n",
    "        prepare_data_for_train_op.outputs['time_series_identifier_column']\n",
    "      ),\n",
    "      time_series_attribute_columns=(\n",
    "        prepare_data_for_train_op.outputs['time_series_attribute_columns']\n",
    "      ),\n",
    "      available_at_forecast_columns=(\n",
    "        prepare_data_for_train_op.outputs['available_at_forecast_columns']\n",
    "      ),\n",
    "      unavailable_at_forecast_columns=(\n",
    "        prepare_data_for_train_op.outputs['unavailable_at_forecast_columns']\n",
    "      ),\n",
    "      column_transformations=(\n",
    "        prepare_data_for_train_op.outputs['column_transformations']\n",
    "      ),\n",
    "      dataset=dataset_create_op.outputs['dataset'],\n",
    "      target_column=prepare_data_for_train_op.outputs['target_column'],\n",
    "      time_column=prepare_data_for_train_op.outputs['time_column'],\n",
    "      forecast_horizon=forecast_horizon,\n",
    "      data_granularity_unit=(\n",
    "          prepare_data_for_train_op.outputs['data_granularity_unit']\n",
    "      ),\n",
    "      data_granularity_count=(\n",
    "          prepare_data_for_train_op.outputs['data_granularity_count']\n",
    "      ),\n",
    "      budget_milli_node_hours=budget_milli_node_hours,\n",
    "      project=project,\n",
    "      location=location,\n",
    "      optimization_objective=optimization_objective,\n",
    "  )\n",
    "\n",
    "\n",
    "  # prediction workflow:\n",
    "  prediction_validation = forecasting.ForecastingValidationOp(\n",
    "      input_tables=prediction_input_table_specs,\n",
    "      validation_theme='FORECASTING_PREDICTION')\n",
    "  prediction_preprocess = forecasting.ForecastingPreprocessingOp(\n",
    "      project=project,\n",
    "      input_tables=prediction_input_table_specs,\n",
    "      preprocessing_bigquery_dataset=preprocessing_bigquery_dataset)\n",
    "  prediction_preprocess.after(prediction_validation)\n",
    "  predict_table_path_op = get_predict_table_path(\n",
    "      prediction_preprocess.outputs['preprocess_metadata'])\n",
    "  model_batch_predict_op = gcc_aip.ModelBatchPredictOp(\n",
    "      model=train_op.outputs['model'],\n",
    "      job_display_name='prediction',\n",
    "      bigquery_source_input_uri=predict_table_path_op.outputs['preprocess_bq_uri'],\n",
    "      instances_format='bigquery',\n",
    "      predictions_format='bigquery',\n",
    "      project=project,\n",
    "      location=location,\n",
    "      bigquery_destination_output_uri=f'bq://{project}.{batch_predict_bigquery_dataset}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88736e75-da5e-4469-b8d4-8d56a219ccb7",
   "metadata": {},
   "source": [
    "### Compile the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05398d6d-ad8c-4144-ab28-94aec89d9eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "                            package_path='forecasting_pipeline_spec.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905dc8f2-c49a-4407-a2fc-899397220085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary table is required by training and prediction workflow\n",
    "primary_table_uri = 'bq://<project-id>.iowa_liquor_sales_dataset.sales_table'  # @param {type: 'string'} <---CHANGE THIS\n",
    "primary_table_specs = {  # <---CHANGE THIS\n",
    "    'bigquery_uri': primary_table_uri,\n",
    "    'table_type': 'FORECASTING_PRIMARY',\n",
    "    'forecasting_primary_table_metadata': {\n",
    "        'time_column': 'datetime',\n",
    "        'target_column': 'gross_quantity',\n",
    "        'time_series_identifier_columns': ['product_id', 'location_id'],\n",
    "        'unavailable_at_forecast_columns': ['sale_dollars', 'state_bottle_cost', 'state_bottle_retail', 'pack', 'bottle_volume_ml', 'volume_sold_liters', 'volume_sold_gallons'],\n",
    "        'time_granularity': {'unit': 'DAY', 'quantity': 1 },\n",
    "        'predefined_splits_column': 'ml_use'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Attribute tables are optional\n",
    "attribute_table_specs_list = []  # <---CHANGE THIS\n",
    "attribute_table_uri1 = 'bq://<project-id>.iowa_liquor_sales_dataset.product_table'  # @param {type: 'string'} <---CHANGE THIS\n",
    "attribute_table_specs_list.append({\n",
    "    'bigquery_uri': attribute_table_uri1,\n",
    "    'table_type': 'FORECASTING_ATTRIBUTE',\n",
    "    'forecasting_attribute_table_metadata': {\n",
    "        'primary_key_column': 'product_id'\n",
    "    }\n",
    "})\n",
    "\n",
    "attribute_table_uri2 = 'bq://<project-id>.iowa_liquor_sales_dataset.location_table'  # @param {type: 'string'} <---CHANGE THIS\n",
    "attribute_table_specs_list.append({\n",
    "    'bigquery_uri': attribute_table_uri2,\n",
    "    'table_type': 'FORECASTING_ATTRIBUTE',\n",
    "    'forecasting_attribute_table_metadata': {\n",
    "        'primary_key_column': 'location_id'\n",
    "    }\n",
    "})\n",
    "\n",
    "# Plan table is required by prediction workflow\n",
    "plan_table_uri = 'bq://<project-id>.iowa_liquor_sales_dataset.plan_table'  # @param {type: 'string'} <---CHANGE THIS\n",
    "plan_table_specs = {  # <---CHANGE THIS\n",
    "    'bigquery_uri': plan_table_uri,\n",
    "    'table_type': 'FORECASTING_PLAN'\n",
    "}\n",
    "\n",
    "# Optional BigQuery dataset for saving the preprocessing output tables.\n",
    "# If empty, a new dataset will be created by the preprocessing component.\n",
    "PREPROCESS_OUTPUT_DATASET = 'iowa_liquor_sales_output'  # @param {type: 'string'} <---CHANGE THIS\n",
    "\n",
    "# Optional Bigquery dataset for saving the batch predcition output table.\n",
    "BATCH_PREDICT_OUTPUT_DATASET = 'iowa_liquor_sales_output'  # @param {type: 'string'} <---CHANGE THIS\n",
    "\n",
    "TRAINING_INPUT = [primary_table_specs]\n",
    "TRAINING_INPUT.extend(attribute_table_specs_list)\n",
    "\n",
    "PREDICTION_INPUT = TRAINING_INPUT.copy()\n",
    "PREDICTION_INPUT.append(plan_table_specs)\n",
    "\n",
    "FORECAST_HORIZON = 7  # @param {type: 'int'} <---CHANGE THIS\n",
    "TRAINING_BUDGET_MILLI_NODE_HOURS = 1000  # @param {type: 'int'} <---CHANGE THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a70360-454c-44bd-bbed-a70fa8aa9f23",
   "metadata": {},
   "source": [
    "### Submit the pipeline job\n",
    "Here, we'll create an API client using the API key you generated.\n",
    "\n",
    "Then, we'll submit the pipeline job by passing the compiled spec to the create_run_from_job_spec() method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbac0f-2528-46fe-a913-288d6bfbf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "\n",
    "api_client = AIPlatformClient(project_id=PROJECT_ID, region=LOCATION,)\n",
    "\n",
    "parameter_values = {\n",
    "    'project': PROJECT_ID,\n",
    "    'location': LOCATION,\n",
    "    'training_input_table_specs': TRAINING_INPUT,\n",
    "    'prediction_input_table_specs': PREDICTION_INPUT,\n",
    "    'preprocessing_bigquery_dataset': PREPROCESS_OUTPUT_DATASET,\n",
    "    'batch_predict_bigquery_dataset': BATCH_PREDICT_OUTPUT_DATASET,\n",
    "    'forecast_horizon': FORECAST_HORIZON,\n",
    "    'budget_milli_node_hours': TRAINING_BUDGET_MILLI_NODE_HOURS,\n",
    "}\n",
    "\n",
    "response = api_client.create_run_from_job_spec(\n",
    "    job_spec_path='forecasting_pipeline_spec.json',\n",
    "    parameter_values=parameter_values,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "#    service_account=SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52de2a9-1df4-48fa-b79d-84e1b6436f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
